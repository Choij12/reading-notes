# Web Scraping
## Readings from Web Scrape with Python in 4 minutes, What is Web Scraping, How to scrape websites without getting blocked.
- Web scraping is a technique to automatically access and extract large amounts of information from a website, which can save a huge amount of time and effort.
- An important rule is to read through the website’s Terms and Conditions to understand how you can legally use the data. Most sites prohibit you from using the data for commercial purposes.
- Another important rule is to make sure you are not downloading data at too rapid a rate because this may break the website. You may potentially be blocked from the site as well.
- Start by importing the following libraries.
- Set the url to the website and access the site with our requests library.
- Parse the html with BeautifulSoup so that we can work with a nicer, nested BeautifulSoup data structure.
- Use the method .findAll to locate all of our `<a>` tags.
- Extract the actual link that we want.
- Webscraping is used to get data from a webpage that was intended to be read by a human, not a machine. 
- There's many techniques to do so. Many websites discourage webscraping and have antiscraping mechanisms. 
- The purpose can be for things such as keeping track of price history, keeping track of website changes, research, tracking user post history, etc. 
- Webscraping has potential legal challenges and/or may violate a websites terms of use. Legal challenges, besides the ethical challenges, are copyright infrigement, CFAA act, and tresspass to chattels. 
- If it contains `User-agent: *`, `Disallow://` it means the site doesn’t like and does not want to be scraped.
- Few easy giveaways that you are bot/scraper/crawler – Scraping too fast and too many pages, faster than a human ever can
- Following the same pattern while crawling. For example – go through all pages of search results, and go to each result only after grabbing links to them. No human ever does that.
- Too many requests from the same IP address in a very short time
- Not identifying as a popular browser. You can do this by specifying a ‘User-Agent’.
- Using a user agent string of a very old browser- 
- Make requests through Proxies and rotate them as needed
- Rotate User Agents and corresponding HTTP Request Headers between requests
- Make sure to be beware of Honey Pot Traps
#### Source:
- https://towardsdatascience.com/how-to-web-scrape-with-python-in-4-minutes-bc49186a8460
- https://en.wikipedia.org/wiki/Web_scraping
- https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/
