# Readings: Linear Regressions

- This article covers linear regression in Python.
- Scikit-learn is a powerful Python module for machine learning. It contains function for regression, classification, clustering, model selection and dimensionality reduction. 
- Manu Jeevan explores the boston housing data set and then renames its column names with feature names instead of just numbers. 
- He explores the boston data set using `.DESCR`, his goal was to predict the housing prices using the given features.
- He uses Scikit learn to fit linear regression to the entire data set and calculates the mean squared error within the datasets.
- Jeevan makes a train-test split and calculates the mean squared error for his training data and test data.
- He then splits up the data into training data and test/verification data which is fed into `predict()`, possibly along with the training data using `sklearn.cross_validation.train_test_split()`
- He then is able to randomly and balancedly splits up the data. 
- Jeevan then makes a residual plot, which is an prediction error plot -- for each row of data that's fed into the model.
- If the residuals for the test dataset don't visually have the same behavior/shape/spread/variability as the training dataset's residuals in the plot, then that might indicate that the model is a poor predictor of the test dataset. 
- And because the test dataset is assumed to be representative of future datapoints, if it can't even predict the test dataset, it's probably not going to do well for making real world predictions either.
- Jeevan then plots the residuals for his training and test datasets.
